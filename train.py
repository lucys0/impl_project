import argparse
import os
import torch
import torch.nn as nn
import gym
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
import cv2
from model import Model, Decoder
from sprites_env.envs import sprites
from torchvision.utils import save_image
import torchvision
from torch.utils.tensorboard import SummaryWriter
import time
from dataset import *

def train(model, batch, optimizer, decoder_optimizer):
    optimizer.zero_grad()
    decoder_optimizer.zero_grad()
    loss = 0.0
    decoded_loss = 0.0

    for obs, reward_targets in zip(batch['obs'], batch['rewards']):
        reward_predicted = model(obs).squeeze()
        loss += model.criterion(reward_predicted, reward_targets)
        
        encoded_img = model.encoder(obs[-1][None, None, :].detach().clone())
        decoded_img = model.decoder(encoded_img).squeeze() 
        decoded_loss += model.criterion(decoded_img, obs[-1])
    
    avg_loss = loss / len(batch) # does this work?
    avg_decoded_loss = decoded_loss / len(batch)

    avg_loss.backward()
    optimizer.step() 
    avg_decoded_loss.backward()
    decoder_optimizer.step()

    return avg_loss.item(), decoded_img[None, :], avg_decoded_loss.item()

# def test(model, states, decoder_optimizer, obs):
#     states = 
#     decoded_img = model.decoder(states)
#     decoder_optimizer.zero_grad()
#     decoded_loss = model.criterion(decoded_img, obs[-1])
#     decoded_loss.backward()
#     decoder_optimizer.step()

#     return decoded_loss, decoded_img

# argument parser
def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--learning_rate', type=float, default=1e-3)
    parser.add_argument('--image_resolution', type=int, default=64)
    parser.add_argument('--time_steps', type=int, default=5)
    parser.add_argument('--tasks', type=int, default=1)
    parser.add_argument('--conditioning_frames', type=int, default=2)
    parser.add_argument('--num_epochs', type=int, default=30)
    parser.add_argument('--batch_size', type=int, default=2)
    parser.add_argument('--env', type=str, default='Sprites-v0')
    args = parser.parse_args()
    return args

# create a directory to save the results
def make_dir():
    image_dir = 'Decoded_images'
    if not os.path.exists(image_dir):
        os.makedirs(image_dir)

# save the reconstructed images as generated by the model
def save_decod_img(img, epoch):
    img = img.view(-1, 64, 64)
    save_image(img, './Decoded_images/epoch{}.png'.format(epoch))

def main():
    # parse arguments
    args = parse_args()

    f = args.conditioning_frames
    t = args.time_steps
    assert t > f

    log_dir = 'runs/num_epochs=' + str(args.num_epochs) + '_time_steps=' + str(t) + '_frames=' + str(f) + '_lr=' + str(args.learning_rate) + '_batch_size=' + str(args.batch_size) + '||' + time.strftime("%d-%m-%Y_%H-%M-%S")
    if not(os.path.exists(log_dir)):
        os.makedirs(log_dir)
    writer = SummaryWriter(log_dir=log_dir)

    # load data
    dl, traj_images, ground_truth = dataloader(args.image_resolution, t, args.batch_size, f)

    # initialize the environment
    env = gym.make(args.env)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    traj_images = traj_images.to(device)

    model = Model(t, f+1, args.tasks, args.image_resolution, device).to(device)
    make_dir()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)
    decoder_optimizer = torch.optim.Adam(model.decoder.parameters(), lr=args.learning_rate)
    train_loss = []
    train_decoded_loss = []

    for epoch in range(args.num_epochs):
        running_loss = 0.0
        running_decoded_loss = 0.0
        for batch in dl:
            # print(batch)
            loss, decoded_img, decoded_loss = train(model, batch, optimizer, decoder_optimizer) # here it's assumed that there's only one task - fix it?
            running_loss += loss
            running_decoded_loss += decoded_loss

        # print or store data
        running_loss = running_loss / len(dl)
        print('Epoch: {} \tLoss: {:.6f}'.format(epoch, running_loss))
        train_loss.append(running_loss)

        running_decoded_loss = running_decoded_loss / len(dl)
        train_decoded_loss.append(running_decoded_loss)

        writer.add_scalar('Loss/train', running_loss, epoch)
        writer.add_scalar('Loss/decoded', running_decoded_loss, epoch)

        if epoch % 5 == 0:
            # print("----", decoded_img.max())
            # print("obs[-1]: ", obs[-1].max(), "||", obs[-1].min())
            # print("decoded_img: ", decoded_img.max(), "||", decoded_img.min())
            
            decoded_img = (decoded_img + 1.0) * 255.0 / 2.0 
            # save_decod_img(decoded_img.unsqueeze(0).cpu().data, epoch)
            writer.add_image('decoded_epoch{}'.format(epoch), decoded_img.to(torch.uint8))
            # input = (obs[-1][None, :] + 1.0) * 255.0 / 2.0
            # writer.add_image('input_epoch{}'.format(epoch), input.to(torch.uint8))


    # visualize results: loss
    # plt.figure()
    # plt.plot(train_loss)
    # plt.title('Train Loss')
    # plt.xlabel('Epochs')
    # plt.ylabel('Loss')
    # plt.savefig('train_loss.png')

    # plt.figure()
    # plt.plot(train_decoded_loss)
    # plt.title('Decoder Loss')
    # plt.xlabel('Epochs')
    # plt.ylabel('Decoded Loss')
    # plt.savefig('decoded_loss.png')

    # decode and generate images with respect to reward functions
    output = model.test_decode(traj_images) 
    
    output = (output + 1.0) * 255 / 2.0    

    # print("*****", output.max())
    img = make_image_seq_strip([output[None, :, None].repeat(3, axis=2).astype(np.float32)], sep_val=255.0).astype(np.uint8)   
    # cv2.imwrite("decode.png", img[0].transpose(1, 2, 0))
    writer.add_image('ground_truth', ground_truth)
    writer.add_image('test_decoded', img[0])
    # writer.add_image('test', output[-1][None, :].astype(np.uint8))
    # print("&&&&", model.criterion(torch.from_numpy(img[0]), torch.from_numpy(temp)).item())
    writer.flush()

if __name__ == '__main__':
    main()
